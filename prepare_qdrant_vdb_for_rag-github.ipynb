{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Qdrant vector database for RAG"
      ],
      "metadata": {
        "id": "tJ-kYxJKQBMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "uB7ZgRurLBWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKubDKvGH7TP",
        "outputId": "30327551-3da9-4c03-e8f4-8aa4dba777bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8892d691",
        "outputId": "b9b858ac-f068-4dd3-dbeb-bf1c4f4283f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.75.1)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\n",
            "Collecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.11.9)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant-client) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, qdrant-client\n",
            "Successfully installed portalocker-3.2.0 qdrant-client-1.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHEKX6oy6TvL",
        "outputId": "021cacd8-afc6-4ec7-d4fc-6d9239ef3ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "pip install openai tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Qdrant"
      ],
      "metadata": {
        "id": "NlLv9CB8LFbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tNTFvDfIy-sr"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BYB_b_rU0r4z"
      },
      "outputs": [],
      "source": [
        "QDRANT_URL = 'XXXX'\n",
        "QDRANT_API_KEY = 'XXXX'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COLLECTION_NAME = \"harry_potter\""
      ],
      "metadata": {
        "id": "huvASDdnPLhX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "638d2a1a"
      },
      "outputs": [],
      "source": [
        "qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "collection_name = COLLECTION_NAME\n",
        "qdrant_client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=models.VectorParams(size=3072, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "print(f\"Collection '{collection_name}' created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load PDF file and convert into chunks"
      ],
      "metadata": {
        "id": "5srwOaJyLM9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zql4tFcy4TwZ"
      },
      "outputs": [],
      "source": [
        "import pymupdf\n",
        "import re\n",
        "import nltk\n",
        "from typing import List, Dict, Any, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYSfFQG-4Z5X",
        "outputId": "bebb051a-689a-417b-b8db-32ad159bb58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u7VIXDp4XcT",
        "outputId": "d017f0be-931a-434f-fb95-1d0dba4a6eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l0WNb12K4SBe"
      },
      "outputs": [],
      "source": [
        "def load_pdf_text_with_context(pdf_path: str, book_title: str) -> Tuple[List[Tuple[str, int]], str]:\n",
        "    # Load pdf file into text with page number\n",
        "    page_texts_with_context = []\n",
        "    try:\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        for page_num, page in enumerate(doc, start=1):\n",
        "            text = page.get_text(\"text\")\n",
        "            page_texts_with_context.append((text, page_num))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "    return page_texts_with_context, book_title\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    # Clean text of multiple whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def create_chunks_with_metadata(\n",
        "    page_texts_with_context: List[Tuple[str, int]],\n",
        "    book_title: str,\n",
        "    chunk_size: int = 1000,\n",
        "    overlap: int = 200\n",
        ") -> List[Dict[str, Any]]:\n",
        "    # Cut text into chunks with overlap, avoid cut mid sentence, include metadata\n",
        "    chunk_list = []\n",
        "\n",
        "    # Process text page by page to get page number\n",
        "    for page_text, page_num in page_texts_with_context:\n",
        "        cleaned_text = clean_text(page_text)\n",
        "        sentences = nltk.sent_tokenize(cleaned_text)\n",
        "        current_chunk_sentences = []\n",
        "        current_word_count = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            words = sentence.split()\n",
        "            sentence_word_count = len(words)\n",
        "\n",
        "            # When chunk reaches the defined chunk size\n",
        "            if current_word_count + sentence_word_count > chunk_size and current_chunk_sentences:\n",
        "                chunk_text = \" \".join(current_chunk_sentences)\n",
        "                chunk_list.append({\n",
        "                    \"text\": chunk_text,\n",
        "                    \"metadata\": {\n",
        "                        \"source\": book_title,\n",
        "                        \"page_number\": page_num,\n",
        "                        \"start_sentence\": current_chunk_sentences[0][:30] + \"...\",\n",
        "                    }\n",
        "                })\n",
        "\n",
        "                # Implement overlap for the next chunk\n",
        "                overlap_word_count = 0\n",
        "                temp_buffer = []\n",
        "                # Keep adding sentences to the buffer until exceed the overlap word count\n",
        "                for s in reversed(current_chunk_sentences):\n",
        "                    s_words = s.split()\n",
        "                    if overlap_word_count + len(s_words) <= overlap:\n",
        "                        temp_buffer.insert(0, s)\n",
        "                        overlap_word_count += len(s_words)\n",
        "                    else:\n",
        "                        # If no sentences in the buffer yet, need to include this one,\n",
        "                        if not temp_buffer:\n",
        "                            temp_buffer.insert(0, s)\n",
        "                            overlap_word_count += len(s_words)\n",
        "                        break\n",
        "\n",
        "                current_chunk_sentences = temp_buffer\n",
        "                current_word_count = overlap_word_count\n",
        "\n",
        "            # Add the current sentence to the chunk\n",
        "            current_chunk_sentences.append(sentence)\n",
        "            current_word_count += sentence_word_count\n",
        "\n",
        "        # Finalize the last chunk of the page\n",
        "        if current_chunk_sentences:\n",
        "            chunk_text = \" \".join(current_chunk_sentences)\n",
        "            chunk_list.append({\n",
        "                \"text\": chunk_text,\n",
        "                \"metadata\": {\n",
        "                    \"source\": book_title,\n",
        "                    \"page_number\": page_num,\n",
        "                    \"start_sentence\": current_chunk_sentences[0][:30] + \"...\",\n",
        "                }\n",
        "            })\n",
        "\n",
        "    return chunk_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nN-zTG4I7bmR"
      },
      "outputs": [],
      "source": [
        "PDF_PATH = 'harry_potter_the_complete_collection.pdf'\n",
        "\n",
        "BOOK_TITLE = \"Harry Potter: The Complete Collection\"\n",
        "\n",
        "\n",
        "page_data, title = load_pdf_text_with_context(PDF_PATH, BOOK_TITLE)\n",
        "\n",
        "chunks_with_meta = create_chunks_with_metadata(\n",
        "    page_texts_with_context=page_data,\n",
        "    book_title=title,\n",
        "    chunk_size=1000,\n",
        "    overlap=200\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_with_meta[2262]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qea7FkbqZ_o0",
        "outputId": "1a7cc67e-0df3-427d-fce6-85f13fb41b84"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'till-dawn end-of-exams celebration in the common room. Harry barely heard them. He scrambled through the portrait hole while they were still arguing about how many black-market butterbeers they would need and was climbing back out of it, the Invisibility Cloak and Sirius’s knife secure in his bag, before they noticed he had left them. “Harry, d’you want to chip in a couple of Galleons? Harold Dingle reckons he could sell us some firewhisky . . .” But Harry was already tearing away back along the corridor, and a couple of minutes later was jumping the last few stairs to join Ron, Hermione, Ginny, and Luna, who were huddled together at the end of Umbridge’s corridor. “Got it,” he panted. “Ready to go, then?” “All right,” whispered Hermione as a gang of loud sixth years passed them. “So Ron — you go and head Umbridge off. . . . Ginny, Luna, if you can start moving people out of the corridor. . . . Harry and I will get the Cloak on and wait until the coast is clear . . .” Ron strode away, his bright red hair visible right to the end of the passage. Meanwhile, Ginny’s equally vivid head bobbed between the jostling students surrounding them in the other direction, trailed by Luna’s blonde one. “Get over here,” muttered Hermione, tugging at Harry’s wrist and pulling him back into a recess where the ugly stone head of a medieval wizard stood muttering to itself on a column. “Are — are you sure you’re okay, Harry? You’re still very pale . . .” “I’m fine,” he said shortly, tugging the Invisibility Cloak from out of his bag. In truth, his scar was aching, but not so badly that he thought Voldemort had yet dealt Sirius a fatal blow. It had hurt much worse than this when Voldemort had been punishing Avery. . . . “Here,” he said. He threw the Invisibility Cloak over both of them and they stood listening carefully over the Latin mumblings of the bust in front of them. “You can’t come down here!” Ginny was calling to the crowd. “No, sorry, you’re going to have to go round by the swiveling staircase, someone’s let off',\n",
              " 'metadata': {'source': 'Harry Potter: The Complete Collection',\n",
              "  'page_number': 2278,\n",
              "  'start_sentence': 'till-dawn end-of-exams celebra...'}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_with_meta[0][\"metadata\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3jFtFrKatrV",
        "outputId": "d40a6c38-505c-4f75-fc75-9bd5cd3c658d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'Harry Potter: The Complete Collection',\n",
              " 'page_number': 6,\n",
              " 'start_sentence': 'CONTENTS Harry Potter and the ...'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create sentence embeddings with OpenAI embedding model"
      ],
      "metadata": {
        "id": "0iIeQo5XPJFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nDrEhX4SLEIG"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from typing import List, Dict, Any\n",
        "from qdrant_client.models import PointStruct\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "59Ep3gRXLLIW"
      },
      "outputs": [],
      "source": [
        "OPENAI_KEY = 'XXXX'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f50p0rJPLuwk"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIMENSION = 3072\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-3-large\"\n",
        "BATCH_SIZE = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mld_d1z67NdI"
      },
      "outputs": [],
      "source": [
        "def batch_embed_and_create_points(chunks: List[Dict[str, Any]]) -> List[PointStruct]:\n",
        "    # Batch embed chunks using embedding model and create pointstruct for qdrant upsert\n",
        "\n",
        "    openai_client = OpenAI(api_key=OPENAI_KEY)\n",
        "\n",
        "    all_qdrant_points = []\n",
        "\n",
        "    for i in range(0, len(chunks), BATCH_SIZE):\n",
        "        batch = chunks[i:i + BATCH_SIZE]\n",
        "        batch_texts = [chunk['text'] for chunk in batch]\n",
        "\n",
        "        try:\n",
        "            # Create embedding for each batch\n",
        "            print(f\"Embedding batch {i//BATCH_SIZE + 1} of {len(chunks) // BATCH_SIZE + 1}...\")\n",
        "            embedding_response = openai_client.embeddings.create(\n",
        "                input=batch_texts,\n",
        "                model=EMBEDDING_MODEL_NAME,\n",
        "                dimensions=EMBEDDING_DIMENSION\n",
        "            )\n",
        "\n",
        "            # Create poinstruct\n",
        "            for j, chunk in enumerate(batch):\n",
        "                vector = embedding_response.data[j].embedding\n",
        "                payload = chunk[\"metadata\"].copy()\n",
        "                payload[\"content\"] = chunk[\"text\"] # Store the full text chunk\n",
        "\n",
        "                global_index = i + j\n",
        "\n",
        "                all_qdrant_points.append(\n",
        "                    PointStruct(\n",
        "                        id=global_index,\n",
        "                        vector=vector,\n",
        "                        payload=payload,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during embedding: {e}\")\n",
        "            continue\n",
        "\n",
        "        print('Sleeping for 5s')\n",
        "        time.sleep(5) # avoids rate limit\n",
        "\n",
        "    return all_qdrant_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA7zdU3N2F-m",
        "outputId": "c7423ce6-77e6-43a1-b002-de56f841c018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding batch 1 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 2 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 3 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 4 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 5 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 6 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 7 of 8...\n",
            "Sleeping for 5s\n",
            "Embedding batch 8 of 8...\n",
            "Sleeping for 5s\n"
          ]
        }
      ],
      "source": [
        "all_qdrant_points = batch_embed_and_create_points(chunks_with_meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upsert vectors to Qdrant"
      ],
      "metadata": {
        "id": "vmFCyOK2P0vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QDRANT_UPSERT_BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "NGkgBqY1PUx2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_upsert_points(client: QdrantClient, COLLECTION_NAME: str, QDRANT_UPSERT_BATCH_SIZE: int, points: List[PointStruct]):\n",
        "    total_points = len(points)\n",
        "    print(f\"Total points to upsert: {total_points}. Upserting in batches of {QDRANT_UPSERT_BATCH_SIZE}.\")\n",
        "\n",
        "    for i in range(0, total_points, QDRANT_UPSERT_BATCH_SIZE):\n",
        "        batch = points[i:i + QDRANT_UPSERT_BATCH_SIZE]\n",
        "\n",
        "        print(f\"-> Upserting batch {i//QDRANT_UPSERT_BATCH_SIZE + 1} ({len(batch)} points)...\")\n",
        "\n",
        "        try:\n",
        "            operation_info = client.upsert(\n",
        "                collection_name=COLLECTION_NAME,\n",
        "                wait=True,\n",
        "                points=batch,\n",
        "            )\n",
        "            print(f\"   Batch {i//QDRANT_UPSERT_BATCH_SIZE + 1} upserted. Status: {operation_info.status.name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Error upserting batch {i//QDRANT_UPSERT_BATCH_SIZE + 1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(\"All point batches processed.\")"
      ],
      "metadata": {
        "id": "bIMMTiHEOOcl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_upsert_points(qdrant_client, COLLECTION_NAME, QDRANT_UPSERT_BATCH_SIZE, all_qdrant_points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWQv1KdzPkg7",
        "outputId": "74fe30b3-63df-4c43-cbe8-c93f24da4e7c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total points to upsert: 3604. Upserting in batches of 256.\n",
            "-> Upserting batch 1 (256 points)...\n",
            "   Batch 1 upserted. Status: COMPLETED\n",
            "-> Upserting batch 2 (256 points)...\n",
            "   Batch 2 upserted. Status: COMPLETED\n",
            "-> Upserting batch 3 (256 points)...\n",
            "   Batch 3 upserted. Status: COMPLETED\n",
            "-> Upserting batch 4 (256 points)...\n",
            "   Batch 4 upserted. Status: COMPLETED\n",
            "-> Upserting batch 5 (256 points)...\n",
            "   Batch 5 upserted. Status: COMPLETED\n",
            "-> Upserting batch 6 (256 points)...\n",
            "   Batch 6 upserted. Status: COMPLETED\n",
            "-> Upserting batch 7 (256 points)...\n",
            "   Batch 7 upserted. Status: COMPLETED\n",
            "-> Upserting batch 8 (256 points)...\n",
            "   Batch 8 upserted. Status: COMPLETED\n",
            "-> Upserting batch 9 (256 points)...\n",
            "   Batch 9 upserted. Status: COMPLETED\n",
            "-> Upserting batch 10 (256 points)...\n",
            "   Batch 10 upserted. Status: COMPLETED\n",
            "-> Upserting batch 11 (256 points)...\n",
            "   Batch 11 upserted. Status: COMPLETED\n",
            "-> Upserting batch 12 (256 points)...\n",
            "   Batch 12 upserted. Status: COMPLETED\n",
            "-> Upserting batch 13 (256 points)...\n",
            "   Batch 13 upserted. Status: COMPLETED\n",
            "-> Upserting batch 14 (256 points)...\n",
            "   Batch 14 upserted. Status: COMPLETED\n",
            "-> Upserting batch 15 (20 points)...\n",
            "   Batch 15 upserted. Status: COMPLETED\n",
            "All point batches processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_points = qdrant_client.retrieve(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    ids=[1000],\n",
        "    with_payload=True\n",
        ")"
      ],
      "metadata": {
        "id": "ppPiyValZIYK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_points"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOJBX5lyd5l7",
        "outputId": "65fbf873-82f8-4b88-f6ab-d0472623b1e9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Record(id=1000, payload={'source': 'Harry Potter: The Complete Collection', 'page_number': 1014, 'start_sentence': 'then” — Mr. Weasley handed ove...', 'content': 'then” — Mr. Weasley handed over the kettle and a couple of saucepans — “and the rest of us will get some wood for a fire?” “But we’ve got an oven,” said Ron. “Why can’t we just —” “Ron, anti-Muggle security!” said Mr. Weasley, his face shining with anticipation. “When real Muggles camp, they cook on fires outdoors. I’ve seen them at it!” After a quick tour of the girls’ tent, which was slightly smaller than the boys’, though without the smell of cats, Harry, Ron, and Hermione set off across the campsite with the kettle and saucepans. Now, with the sun newly risen and the mist lifting, they could see the city of tents that stretched in every direction. They made their way slowly through the rows, staring eagerly around. It was only just dawning on Harry how many witches and wizards there must be in the world; he had never really thought much about those in other countries. Their fellow campers were starting to wake up. First to stir were the families with small children; Harry had never seen witches and wizards this young before. A tiny boy no older than two was crouched outside a large pyramid-shaped tent, holding a wand and poking happily at a slug in the grass, which was swelling slowly to the size of a salami. As they drew level with him, his mother came hurrying out of the tent. “How many times, Kevin? You don’t — touch — Daddy’s — wand — yecchh!” She had trodden on the giant slug, which burst. Her scolding carried after them on the still air, mingling with the little boy’s yells — “You bust slug! You bust slug!” A short way farther on, they saw two little witches, barely older than Kevin, who were riding toy broomsticks that rose only high enough for the girls’ toes to skim the dewy grass. A Ministry wizard had already spotted them; as he hurried past Harry, Ron, and Hermione he muttered distractedly, “In broad daylight! Parents having a lie-in, I suppose —” Here and there adult wizards and witches were emerging from their tents'}, vector=None, shard_key=None, order_value=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}